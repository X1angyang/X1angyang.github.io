<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow on Life Is Fantastic</title>
    <link>https://X1angyang.github.io/categories/tensorflow/</link>
    <description>Recent content in tensorflow on Life Is Fantastic</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 25 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://X1angyang.github.io/categories/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title> tensorflow: Histopathologic image</title>
      <link>https://X1angyang.github.io/blog/cancer/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://X1angyang.github.io/blog/cancer/</guid>
      <description>识别组织切片是癌症或者正常。
数据：https://www.kaggle.com/c/histopathologic-cancer-detection/data
组织切片数据，来识别是癌症组织还是正常组织，我觉得是没多大意义的。因为在临床上，基本不可能获得一个病人的组织切片来检测是否患病，检测是否患病的代价太大是没有意义的。组织切片更多的是研究机体组织层面的情况，来研究细胞的作用机制，形态等。
这里就不深究。
网站给的数据非常庞大，训练集20多w张图片，测试集也有6w多。由于我的电脑太菜，我只用了1w张作训练集。
给的图片非常规整，全部为96 * 96像素的。因为想直接借鉴lenet5结构，我试了下直接resize成32 * 32的图片，但我自己感官上看图片变的非常模糊，96 / 32 =3， 损失了2/3的信息，我觉得可能效果不理想，就没有这样做。直接保存了96 * 96像素的大小。
先来看一下数据：
虽然有细胞生物学和生物化学以及分子生物学的基础，但是我没有真正看过组织切片，一开始也是没有看出正常和癌症的区别。后来由癌细胞的特性，观察可能是癌症组织会入侵到正常组织中，造成细胞形态不正常，还有大小吧。。。不是很清楚。染色什么的也不能分辨是癌症还是正常组织。总之，对一个没有看切片经验的人来说，还是比较困难的。
这次分类用的结构和之前的猫狗大战一样，是改良版的vgg16。不知道的小伙伴可以看往期的专栏，那里有改良版的vgg16的结构。
但是由于输入像素为96*96*3的图片，比猫狗大战的64*64*3多的很多，导致训练比较慢，总共训练了不到1w轮，测试集85%左右的正确率。
做了3个tensorflow的实战，还是有一些感触的。
总体来说，卷积步骤能够赋予大多数网络一定的学习的能力，但是，个人的网络往往学习能力都不强。这时候不得不借助成熟的经典网络，但是，随之而来的问题是经典网络往往对输入图片的大小都有要求，在转换的过程中，会损失或者失去很多信息。比如说原vgg16的输入是224 * 224 * 3，如果将组织切片数据转换为224，则会加入一些预测的信息，这一定会对结果造成影响。由大图片转换为小图片更可能丢失信息。再者，成熟的网络大多数都是深度网络，卷积池化和全连接加起来有接近20层，这在pc上很难调试和训练（没试过GPU）。
最近看了一篇迁移学习的文章，很有用，可能会试试看。</description>
    </item>
    
    <item>
      <title> Is there a columnar cactus?</title>
      <link>https://X1angyang.github.io/blog/columnar/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://X1angyang.github.io/blog/columnar/</guid>
      <description>分类的数据，鉴定图片是否含有柱状仙人掌。
数据来自：https://www.kaggle.com/c/aerial-cactus-identification/data
网站给的数据图片都很规整，为32*32。图片大概是这样的： 仙人掌一 仙人掌二 无仙人掌
大约能看到一条白色的细线，就是仙人掌了。图片大小比较小，也比较简单。我打算直接用全连接。
全连接结构：
 500个节点 500个节点 2个输出节点  其它的和cat VS dog的参数一样。
这样训练出来的测试集正确率大约为85%。
然后我试了下卷积，
因为是32 * 32的图片，我用的lenet5结构。然后再接上述的全连接，这样训练了大约80000轮，测试集正确率为91%。继续训练至16w轮正确率还是一样。
我觉得可能是提取的特征不够，我将lenet5的卷积核的个数由5和16个改为32和64个，此时，训练大约4w轮就达到了91%的正确率，继续训练至7w轮正确率无变化。
我认为是网络结构的学习度不够吧，想要继续提升，只能改变网络结构，更好的提取特征。</description>
    </item>
    
    <item>
      <title>猫狗分类</title>
      <link>https://X1angyang.github.io/blog/dog_cat/</link>
      <pubDate>Thu, 20 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://X1angyang.github.io/blog/dog_cat/</guid>
      <description>这次神经网络实践的数据来自：https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data
训练数据中，只有猫和狗两种类别。图片共25000张，猫和狗分别12500张。图片都来自于真实场景，图片大小不一致，数据较为复杂。
本来是有测试数据的，但是给的标签错了，所以我直接将训练数据分为测试数据（5000张），训练数据（20000张）
自己的实践之路：
之前的12306数据集让我明白，现成的经典网络结构比自己的好，所以我引用了alexnet。我将图片处理为227*227*3的大小，构建alexnet是神经网络，但是发现结果不是很好。
我又在Kaggle的猫狗数据网站上找到了其他人的分享https://www.kaggle.com/jeffd23/catdognet-keras-convnet-starter/notebook，用的是自改的vgg16，实现方式是keras。一开始我认为我的电脑运算能力不足以计算如此深层的神经网络。抱着试一下的态度，我尝试用tensorflow复现：
前向：
输入图片大小：64*64*3
所有卷积核大小为3*3
所有池化核的大小为2*2
均使用0填充
训练：
学习率：0.0001
正则：0.0001
batch size：16
loss：交叉熵
滑动平均
RMS优化器
vgg16是非常深的神经网络。该修改的版本也差不多。
网络结构：
 3*3*32的卷积 3*3*32的卷积 2*2池化 3*3*64的卷积 3*3*64的卷积 2*2池化 3*3*128的卷积 3*3*128的卷积 2*2池化 3*3*256的卷积 3*3*256的卷积 2*2池化 256个节点的第一层全连接 256个节点的第二层全连接 2个节点的输出层  训练了18000轮，测试集85%的正确率，但是到了10000轮的时候就差不多稳定了。
作者的留言里写道他的正确率大约为90%，而且作者训练的数据只有总共的8%，我对此是有些疑问的。</description>
    </item>
    
    <item>
      <title>Tensorflow在12306的失败记录</title>
      <link>https://X1angyang.github.io/blog/tensorflow_12306/</link>
      <pubDate>Sun, 09 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://X1angyang.github.io/blog/tensorflow_12306/</guid>
      <description>最近想用tensorflow做点实际的东西，最后选取了12306的验证码的识别。网上有很多这种实战，但都是识别26个字母或者10个数字的小项目。当然，在csdn上也有一位博主说他用简单的cnn将12306的验证码识别准确率提升到了95%；相关网络结构和代码没有公布，在他的回答中，都说的是最简单的cnn处理的验证码和汉字。于是，我有了自己实践的念头。
数据：
一开始我是自己做的爬虫，爬取了大约10000张验证码。当时心里美滋滋的，但是随后的标记工作苦不堪言，我标记了大约100张就放弃了这个工作。在网上查的方法有人工打码，当然，这是要钱的，100张1元左右，让我心生退意。我不得已疯狂浏览相关博文，，，，最后终于下载了一万一千多张验证码和相应标签。  处理：
在阅读csdn大神博主的博文后，我想当然的以为最简单的cnn必然有不错的效果，但是我尝试了很多次，修改了很多的网络结构，均以失败告终。正确率都在10%到20%左右。 我开始借鉴一些成熟的网络结构，首先是lenet5，一开始我没有改变图片的大小，自己先用一层卷积将输出大小变为lenet的输入大小，但是没有效果。不得已，我将图片直接转为32*32的大小，最后迭代20多万次，才有50%的正确率（100个分类）。这也是我最后的结果了。 我当然感到不满意，尝试使用alenet的网络结构，但是第一步就把我难住了，alenet的输入是227*227的，而我下载的数据才66*66，直接将图片变大肯定是不行的，我直接放弃了这个网络结构。（后来其它的分类项目中，证实alenet结构不是我这个垃圾PC能运行的）。所以，最后的结果也就50%多一点。  我不知道csdn大神是的网络结构是怎样的，只能说，他们真的很nb，
唉，我还是个入门小白啊，，，，
学到的东西吧： 1.自己的网络结构大多数是不成熟的，往往得不到很好的效果，这时候直接借鉴是不错的选择。 2.学习率衰减的问题。一开始我设置的基础学习率为0.0001，衰减率0.5，300轮更新一次，训练了几千轮后loss一直摆动，正确率也特别低。一直找不到原因，后来发现tensorflow中学习率最多就10负6次，然后就是0了，在之后的训练中，根本没有学习。 3.batch_size的大小设置。这个我一直不知道怎么设置合适的值，一开始没注意，一直是固定的。后来在找原因的时候，一个个查找相关参数的影响。网上说的是太小不好，太大也不好，只能一个个地试。然而还是硬件的问题，自己的电脑让我没心情去试验到底哪个数值比较好。 4.修改已知的网络结构。经典的网络结构往往是不适合自己的数据的，怎么修改成适合自己的成了最大的难题。在北京大学曹健老师的课件里也对lenet网络结构进行了修改以适应mnist的数据。但只是给出了修改的网络结构，没有具体的分析，我捯饬了很久也没找出其中的规律。我一开始自己修改的lenet结构在验证码数据的效果不是很好。我在想，经典的网络结构该怎么修改，这一定是有经验可循的；或者说，这本身就是一个金标准，不可动摇。  generate_tfrecord
import tensorflow as tf from PIL import Image import os tfRecord_train = &amp;quot;./data/train1.tfrecords&amp;quot; image_train_path = &amp;quot;./data/data/&amp;quot; label_train_path = &amp;quot;./data/label.txt&amp;quot; file_dir = &amp;quot;C:/Users/Lenovo/Desktop/python/pachong_test/trian_12306/data/captcha&amp;quot; label_names = os.listdir(file_dir) # 生成tfrecords文件 def write_tfRecord(tfRecordName, image_path, label_path): # 新建一个writer writer = tf.python_io.TFRecordWriter(tfRecordName) num_pic = 0 f = open(label_path, &#39;r&#39;) contents = f.readlines() f.close() # 循环遍历每张图和标签 for content in contents: value = content.</description>
    </item>
    
    <item>
      <title>Tensorflow系列（二）</title>
      <link>https://X1angyang.github.io/blog/tensorflow2/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://X1angyang.github.io/blog/tensorflow2/</guid>
      <description>如图，模拟的数据：在半径为根号2的圆内的点为红色，圆外的点为蓝色，那么，我想要让神经网络试试能不能将这两类数据分开，随机输入一个点，而预测它的颜色
实验需求：python, tensorflow, numpy, random, matplotlib
本次实验参考中国大学mooc
代码分为两个部分，前向传播网络的构建和反向传播网络参数训练。前向传播文件中有：生成参数w和b的函数，自己构建前向传播网络函数，具体代码有很详细的注释。百度云盘文末附上。经过前向传播，我们会得到网络训练的值。然后再反向传播中，令真实值与训练值的距离为loss，在梯度下降法中，经过20000轮的迭代，让loss不断减小，从而训练出w和b。最后向神经网络喂入密集点阵，得到大量值，以0.5为分界线，画出分类界限。得到下图： 可以看到，训练的分类界限基本上是一个以根号2为半径的圆，模型不错。
前向传播：
# coding:utf-8 import tensorflow as tf Input_size = 2 # 输入节点层大小 Node_size = 20 # 中间层节点大小 Output_size = 1 # 输出节点层大小 def get_weight(shape, regularizer): # 获取参数w的函数 w = tf.Variable(tf.truncated_normal(shape, stddev=0.1)) # 随机赋值给w if regularizer is not None: tf.add_to_collection(&amp;quot;losses&amp;quot;, tf.contrib.layers.l2_regularizer(regularizer)(w)) return w def get_b(shape): # 获取偏置b的函数 b = tf.b = tf.Variable(tf.zeros(shape)) # 统一将 bias 初始化为 0 return b def forward(x, regularizer): # 构建前向传播框架 w1 = get_weight([Input_size, Node_size], regularizer) # 获取参数w1 b1 = get_b([Node_size]) # 获取参数b1 y1 = tf.</description>
    </item>
    
    <item>
      <title>Tensorflow系列（一）</title>
      <link>https://X1angyang.github.io/blog/r/</link>
      <pubDate>Mon, 03 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://X1angyang.github.io/blog/r/</guid>
      <description>介绍：
人工神经网络是一种比较优越的分类方法，模拟了神经元的信息传递。虽然咋一听觉得人工神经网络或者人工智能，或者深度学习这些字眼很高大上，离我们很遥远，但是入门理解起来还是很容易的，难的是如任何一门知识一般的深入。 y = [x1 x2] * w1 w2,在实际的神经网络中还会让相乘的结果加上偏置b，再经过激活函数，这样一层神经网络就计算结束了，当然，在实际的网络中， 可能会有很多层， 而每层又会有很多个节点。在整个网络经过：乘积求和，加偏置，过激活函数后，前向传播就结束了。接下来的是反向传播。这里涉及的公式很难懂，就不赘述，记住反向传播的功能：经过反向传播，来调整参数w的值。在tensorflow中，反向传播是不需要我们操心的，只需要一句代码就搞定了。
神经网络的主体步骤大概就是这样，反复地前向，反向计算，直到训练的w能够让计算的结果和实际的结果最接近为止。
tensorflow：
tensorflow使用的数据称作张量，表示多维数组
计算图，tensorflow在计算图中搭建前向，反向传播结构，但是在计算图中不使用数据计算。就好比，我们在计算图中搭建了城市的电路分配的具体线路，而不通电。
会话， tensorflow在会话中传入数据，通过搭建好的计算图训练神经网络，这里就相当于通电正式使用了。
下面介绍几个经常用的函数：
import tensorflow as tf
下面全都以tf表示
tf.Variable()：表示变量，我们在初始话参数w的时候会用到
tf.matmul()：矩阵相乘，在搭建前向传播网络的时候会用到
tf.nn.relu()：激活函数的一种，矩阵相乘的结果一般会经过激活函数（最后一层节点不用）
tf.placeholder()：占位，在搭建网络的时候，我们传入的不是具体的多少维的数据，需要用它来给传入数据占位
tf.reduce_mean(tf.square(计算的结果和实际的距离))：表示损失函数，这是最基本的
tf.train.GradientDescentOptimizer（）.minimize()：反向传播的一种方法，梯度下降，令损失值最小，当然还有其它的方法
tf.global_variables_initializer()：变量的初始化，这是在会话中必须的
tf.Session().run()：会话中的最重要的函数，表示计算特定的参数。
上面差不多就是搭建一个最基本的神经网络中的最重要的函数了。今天先介绍这些，下回上一个简单全连接神经网络的代码。</description>
    </item>
    
  </channel>
</rss>